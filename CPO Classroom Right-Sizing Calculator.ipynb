{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPO Datascience\n",
    "\n",
    "This program is intended for use by the Portland State University Campus Planning Office (CPO).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_school(school_filter, term_filter):\n",
    "    \"\"\"\n",
    "    Loads enrollment csv by term and gnerates a list of unique classes for that \n",
    "    department to check against the campus-wide classroom dataframe.\n",
    "    \"\"\"\n",
    "    cls_filename = 'enrollment_data/CLE-{0}-{1}.csv'.format(school_filter, term_filter)\n",
    "    df_classes = pd.read_csv(cls_filename)\n",
    "    # Filter out PE classes\n",
    "    df_classes = df_classes.loc[df_classes['Schedule_Type_Desc'] != 'Activity']\n",
    "    df_classes['Class_'] = df_classes['Subj'] + \" \" + df_classes['Course'] \n",
    "    valid_class_list = set(df_classes['Class_'].tolist()) # Get only unique values\n",
    "    return valid_class_list\n",
    "\n",
    "def filter_dept_control_CPO_list(term_filter):\n",
    "    \"\"\"\n",
    "    Special condition to check against CPO 2016 departmentally-owned classroom list\n",
    "    \"\"\"\n",
    "    dc_filename = 'classroom_data/CPO_dc_list-{0}.csv'.format(term_filter)\n",
    "    df_dept_control = pd.read_csv(dc_filename)    \n",
    "    sh_filename = 'classroom_data/CPO_gp_share_list-{0}.csv'.format(term_filter)\n",
    "    df_share = pd.read_csv(sh_filename)    \n",
    "    df_dept = pd.concat([df_dept_control, df_share])\n",
    "    df_dept['Classroom'] = df_dept['Building'] + ' ' + df_dept['ROOM'].astype(str)\n",
    "    df_dept = df_dept[['Classroom', 'Dept']]\n",
    "    df_dept.rename(columns={'Dept' : 'Dept_'}, inplace=True)\n",
    "    print(\"== Using Internal CPO 2016 Departmentally-owned classroom information ==\")\n",
    "    return df_dept\n",
    "\n",
    "def filter_dept_control_list(term_filter):\n",
    "    dep_filename = 'classroom_data/dept_control_list-{0}.csv'.format(term_filter)\n",
    "    df_dept = pd.read_csv(dep_filename)    \n",
    "    df_dept['Classroom'] = df_dept[\"Room\"] + \" \" + df_dept[\"Room.1\"]\n",
    "    print(\"== Using DATAMASTER Departmentally-owned classroom information ==\") \n",
    "    return df_dept\n",
    "\n",
    "def filter_AIM_dept_control_list(school_filter, term_filter):\n",
    "    dep_filename = 'classroom_data/AIM-{0}-{1}.csv'.format(school_filter, term_filter)\n",
    "    df_dept = pd.read_csv(dep_filename)    \n",
    "    df_dept['Classroom'] = df_dept[\"acronym\"] + \" \" +df_dept[\"location_code\"]\n",
    "    print(\"== Using AIM Departmentally-owned classroom information ==\") \n",
    "    return df_dept\n",
    "\n",
    "def filter_gp_classrooms(term_filter):\n",
    "    dep_filename = 'classroom_data/GP-classrooms-{0}.csv'.format(term_filter)\n",
    "    df_gp = pd.read_csv(dep_filename)    \n",
    "    df_gp['Classroom'] = df_gp[\"Room\"] + \" \" + df_gp[\"Room.1\"]\n",
    "    print(\"== Using DATAMASTER General Pool classroom information ==\") \n",
    "    return df_gp   \n",
    "\n",
    "def filter_all_classrooms(term_filter):\n",
    "    \"\"\"\n",
    "    Loads datamaster table for ALL classrooms per scheduled term.\n",
    "    \"\"\"\n",
    "    dep_filename = 'classroom_data/GP_DPT-classrooms-{0}.csv'.format(term_filter)\n",
    "    df_all = pd.read_csv(dep_filename)    \n",
    "    df_all['Classroom'] = df_all[\"Room\"] + \" \" + df_all[\"Room.1\"]\n",
    "    print(\"== Using DATAMASTER 'All Classrooms' table S0019 ==\")\n",
    "    return df_all      \n",
    "\n",
    "def filter_class_logic(school_filter, term_filter, classroom_filter, db_decision):\n",
    "    \"\"\"\n",
    "    Controlling logic for filtering departmentally-owned, general pool, or ALL\n",
    "    classroom types. \n",
    "    \"\"\"\n",
    "    if classroom_filter == 'DO':\n",
    "        if db_decision == 'DATAMASTER': \n",
    "            df_dept = filter_dept_control_list(term_filter)\n",
    "            return df_dept\n",
    "        elif db_decision == 'CPO':\n",
    "            CPO_dept_owned = filter_dept_control_CPO_list(term_filter)\n",
    "            return CPO_dept_owned\n",
    "        elif db_decision == 'AIM':\n",
    "            AIM_dept_owned = filter_AIM_dept_control_list(school_filter, term_filter)\n",
    "            return AIM_dept_owned\n",
    "        else: \n",
    "            print('ERROR: Invalid input!')\n",
    "    if classroom_filter == 'GP':\n",
    "        gp_class = filter_gp_classrooms(term_filter)\n",
    "        return gp_class\n",
    "    if classroom_filter == 'ALL':    \n",
    "        all_class = filter_all_classrooms(term_filter)\n",
    "        return all_class\n",
    "\n",
    "def format_date(df_date):\n",
    "    \"\"\"\n",
    "    Splits Meeting times into Days of the week, Start time, and End time using regex\n",
    "    \"\"\"\n",
    "    df_date['Days'] = df_date['Meeting_Times'].str.extract('([^\\s]+)', expand=True)\n",
    "    df_date['Start_Date'] = df_date['Meeting_Dates'].str.extract('^(.*?)-', expand=True)\n",
    "    df_date['End_Date'] = df_date['Meeting_Dates'].str.extract('((?<=-).*$)', expand=True)\n",
    "    df_date['Start_Time'] = df_date['Meeting_Times'].str.extract('(?<= )(.*)(?=-)', expand=True)\n",
    "    df_date['Start_Time'] = pd.to_datetime(df_date['Start_Time'], format='%H%M')\n",
    "    df_date['End_Time'] = df_date['Meeting_Times'].str.extract('((?<=-).*$)', expand=True)\n",
    "    df_date['End_Time'] = pd.to_datetime(df_date['End_Time'], format='%H%M')\n",
    "    df_date['Duration_Hr'] = ((df_date['End_Time'] - df_date['Start_Time']).dt.seconds)/3600\n",
    "    return df_date\n",
    "\n",
    "def format_df_reg(df_reg):\n",
    "    df_reg = df_reg.loc[df_reg['Xlst'] == '']\n",
    "    columns = ['ROOM', 'Actual_Enrl', 'Room_Capacity', 'Weekly_Class_Hours']\n",
    "    df_reg = df_reg[columns]\n",
    "    df_reg['%_Capacity'] = df_reg['Actual_Enrl'] / df_reg['Room_Capacity'].astype(int)\n",
    "    return df_reg\n",
    "\n",
    "def merge_xlist(df_xl):\n",
    "    \"\"\"\n",
    "    Merges courses with a value in Xlist column. Sums Actual_Enrl for totals \n",
    "    column but retains Room Number, Room Capacity, and Weekly Class Hours, as \n",
    "    these numbers are constant. \n",
    "    \"\"\"\n",
    "    df_xl = df_xl.loc[df_xl['Xlst'] != '']\n",
    "    xl_operations = ({'ROOM' : 'max',\n",
    "                      'Actual_Enrl' : 'sum', \n",
    "                      'Room_Capacity' : 'max',\n",
    "                      'Weekly_Class_Hours' : 'max',})\n",
    "    df_xl = df_xl.groupby('Xlst', as_index=False).agg(xl_operations)\n",
    "    df_xl['%_Capacity'] = df_xl['Actual_Enrl'] / df_xl['Room_Capacity'].astype(int)\n",
    "    return df_xl\n",
    "\n",
    "def aggregate(df_agg):\n",
    "    \"\"\"\n",
    "    Main aggegation function of PSU classrooms. Inputs unified dataframe of \n",
    "    crosslisted and non-crosslisted courses. Sums Weekly_Class_Hours and \n",
    "    calculates mean of Room_Capacity and Actual_Enrl.\n",
    "\n",
    "    Performs Optimal 125% Size calculation.\n",
    "    \"\"\"\n",
    "    df_agg['Room_Capacity'] = df_agg['Room_Capacity'].astype(float)\n",
    "    df_agg['Actual_Enrl'] = df_agg['Actual_Enrl'].astype(float)\n",
    "\n",
    "    operations = ({'Weekly_Class_Hours' : 'sum', \n",
    "                   'Room_Capacity' : 'mean', \n",
    "                   'Actual_Enrl' : 'mean',})\n",
    "    df_agg = df_agg.groupby('ROOM', as_index=False).agg(operations)\n",
    "\n",
    "    # Calculate hourly utilizations\n",
    "    df_agg['Class_Hour_Utilization'] = (df_agg['Weekly_Class_Hours']/40.0).astype(float)\n",
    "\n",
    "    # Round optimal size to the nearest 5\n",
    "    df_agg['Optimal_Size'] = 5 * round((df_agg['Actual_Enrl'] * 1.25)/5)\n",
    "    # Optimal size should be a minimum of 10 seats\n",
    "    df_agg.loc[df_agg['Optimal_Size'] < 10.0, 'Optimal_Size'] = 10.0\n",
    "    # 'Bin' figures to fixed ranges. From Ernest Tipton's 201604 Spreadsheet.\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 60.0) & (df_agg['Optimal_Size'] < 75.0), 'Optimal_Size'] = 75.0\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 75.0) & (df_agg['Optimal_Size'] < 80.0), 'Optimal_Size'] = 80.0\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 80.0) & (df_agg['Optimal_Size'] < 100.0), 'Optimal_Size'] = 100.0\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 100.0) & (df_agg['Optimal_Size'] < 150.0), 'Optimal_Size'] = 150.0\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 150.0) & (df_agg['Optimal_Size'] < 200.0), 'Optimal_Size'] = 200.0\n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 200.0) & (df_agg['Optimal_Size'] < 220.0), 'Optimal_Size'] = 220.0  \n",
    "    df_agg.loc[(df_agg['Optimal_Size'] > 220.0) & (df_agg['Optimal_Size'] < 380.0), 'Optimal_Size'] = 380.0\n",
    "    return df_agg\n",
    "\n",
    "def right_sizing(df_rs):\n",
    "    growth_factor = 0.01 * 3 # 1% annual growth over three years\n",
    "    rs_operations = ({'Class_Hour_Utilization' : 'sum'})\n",
    "    df_rs = df_rs.groupby('Optimal_Size', as_index=False).agg(rs_operations)\n",
    "    df_rs['Calibrated_Demand'] = df_rs['Class_Hour_Utilization'] + growth_factor\n",
    "    # Round up to the nearest integer\n",
    "    df_rs['Qty_Classrooms'] = np.ceil(df_rs['Calibrated_Demand'])\n",
    "    df_rs['Qty_Seats'] = df_rs['Optimal_Size'] * df_rs['Qty_Classrooms']\n",
    "    df_rs = df_rs.drop('Class_Hour_Utilization', 1) #Simplify formatting for printing\n",
    "    return df_rs\n",
    "\n",
    "def final_print(df_print, school_print, term_print):\n",
    "    print('===================================================================')\n",
    "    print('Report for {0} - {1}'.format(school_print, term_print))\n",
    "    print(df_print)\n",
    "    print(\"Total Number of Classrooms Needed (Projected): \", df_print['Qty_Classrooms'].sum())\n",
    "    print(\"Total Number of Seats Needed (Projected): \", df_print['Qty_Seats'].sum())\n",
    "    print('===================================================================','\\n')\n",
    "    columns = ['Optimal_Size', 'Key', 'Qty_Classrooms']\n",
    "    df_print['Key'] = term_print\n",
    "    df_print['Optimal_Size'] = df_print['Optimal_Size'].astype(int)\n",
    "    df_print = df_print[columns]\n",
    "    return df_print\n",
    "\n",
    "def plot_graphs(df_grph_lst, school_print, class_type_print):\n",
    "    \"\"\"\n",
    "    Takes a list of dfs per term and plots them in a single figure.\n",
    "    \"\"\"\n",
    "    class_dct = ({'DO' : 'Departmentally-Controlled Classrooms',\n",
    "                  'GP' : 'General Pool Classrooms',\n",
    "                  'ALL': 'Dept-Controlled and General Pool Classrooms'})\n",
    "    df_all = pd.concat(df_grph_lst)\n",
    "    df_group = df_all.groupby(['Optimal_Size', 'Key'])\n",
    "    df_group_plot = df_group.sum().unstack('Key').plot(kind='bar')\n",
    "    df_group_plot.set_xlabel('Classrooms by Size')\n",
    "    df_group_plot.set_ylabel('Number of Classrooms Needed (Projected)')\n",
    "    df_group_plot.set_title('{0} {1}'.format(school_print, class_dct[class_type_print]))\n",
    "    df_group_plot.set_ylim([0, 5]) #Departmental view \n",
    "    #df_group_plot.set_ylim([0, 75]) # Uncomment for FULL CAMPUS VIEW\n",
    "    plt.show()\n",
    "\n",
    "def input_flow():\n",
    "    \"\"\"\n",
    "    Captures main User prompts and inputs\n",
    "    \"\"\"\n",
    "    #terms = ['201604', '201504', '201404', '201304']\n",
    "    terms = ['201604']\n",
    "    school = input(\"Enter desired department for evaluation: GSE or SPH >>> \").upper()\n",
    "    inp_classroom_type = input(\"Filter by Departmentally-Owned, General Pool, or ALL Classrooms? DO/GP/ALL >>> \").upper()\n",
    "    if inp_classroom_type == 'DO':\n",
    "        inp_db = input(\"Choose department ownership by database: CPO/AIM/DATAMASTER >>> \").upper()\n",
    "        if inp_db == 'CPO' or inp_db == 'AIM':\n",
    "            terms = ['201604']\n",
    "    else:\n",
    "        inp_db = \"\"\n",
    "    return terms, school, inp_classroom_type, inp_db\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main program control flow.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('data/PSU_master_classroom.csv')\n",
    "    df = df.fillna('')\n",
    "\n",
    "    df = format_date(df)\n",
    "    # Avoid classes that only occur on a single day\n",
    "    df = df.loc[df['Start_Date'] != df['End_Date']]\n",
    "\n",
    "    # Calculate number of days per week and treat Sunday condition\n",
    "    if 'SU' not in df['Days']:\n",
    "        df['Days_Per_Week'] = df['Days'].str.len()\n",
    "    else:\n",
    "        print('Sunday Condition!')\n",
    "        #ToDO: If sunday does come up, refactor code to address this.\n",
    "\n",
    "    df['Room_Capacity'] = df['Room_Capacity'].apply(lambda x: x if (x != 'No Data Available') else 0)\n",
    "    df['%_Capacity'] = df['Actual_Enrl'].astype(int) / df['Room_Capacity'].astype(int) \n",
    "    #df['Weekly_Class_Hours'] = df['Duration_Hr'] * df['Days_Per_Week']\n",
    "\n",
    "    print('Raw Class list dump:')\n",
    "    print(df[['ROOM', 'Room_Capacity', 'Dept_', 'Class', 'Xlst', 'Actual_Enrl', '%_Capacity']])\n",
    "\n",
    "    # split df into crosslisted and non-crosslisted classes and send them to\n",
    "    # respective functions for cleaning\n",
    "    df_reg = format_df_reg(df)\n",
    "    df_xlist = merge_xlist(df)\n",
    "    # Recombine into one dataframe\n",
    "    df_combined = aggregate(pd.concat([df_reg, df_xlist]))\n",
    "\n",
    "    df_final = right_sizing(df_combined)\n",
    "    df_graph = final_print(df_final, school, term)\n",
    "    graph_dfs.append(df_graph)\n",
    "\n",
    "    plot_graphs(graph_dfs, school, inp_classroom_type)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2827: DtypeWarning: Columns (14,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data 'Jun 13' does not match format '%H%M' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\pandas\\tseries\\tools.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtslib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.datetime_to_datetime64 (pandas\\tslib.c:33358)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-bfca2f9fbca5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[1;31m# Avoid classes that only occur on a single day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start_Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'End_Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bfca2f9fbca5>\u001b[0m in \u001b[0;36mformat_date\u001b[0;34m(df_date)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start_Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start_Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%H%M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'End_Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Meeting_Times'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'((?<=-).*$)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'End_Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'End_Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%H%M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Duration_Hr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'End_Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Start_Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3600\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\pandas\\util\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\pandas\\tseries\\tools.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, coerce, unit, infer_datetime_format)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\pandas\\tseries\\tools.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kms22\\AppData\\Local\\Continuum\\Miniconda3\\envs\\data-science\\lib\\site-packages\\pandas\\tseries\\tools.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                         result = tslib.array_strptime(arg, format, exact=exact,\n\u001b[0;32m--> 380\u001b[0;31m                                                       errors=errors)\n\u001b[0m\u001b[1;32m    381\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mtslib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.array_strptime (pandas\\tslib.c:62796)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'Jun 13' does not match format '%H%M' (match)"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
